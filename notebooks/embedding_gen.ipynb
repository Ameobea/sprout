{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Hit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "93 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "build-essential is already the newest version (12.9ubuntu3).\n",
      "vim is already the newest version (2:8.2.3995-1ubuntu2.17).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 93 not upgraded.\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (2.8.8)\n",
      "Requirement already satisfied: node2vec in /opt/conda/lib/python3.11/site-packages (0.4.6)\n",
      "Requirement already satisfied: python-Levenshtein in /opt/conda/lib/python3.11/site-packages (0.25.1)\n",
      "Requirement already satisfied: nodevectors in /opt/conda/lib/python3.11/site-packages (0.1.23)\n",
      "Requirement already satisfied: emblaze in /opt/conda/lib/python3.11/site-packages (0.10.6)\n",
      "Requirement already satisfied: pymde in /opt/conda/lib/python3.11/site-packages (0.1.18)\n",
      "Requirement already satisfied: gensim<5.0.0,>=4.1.2 in /opt/conda/lib/python3.11/site-packages (from node2vec) (4.3.3)\n",
      "Requirement already satisfied: joblib<2.0.0,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from node2vec) (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.19.5 in /opt/conda/lib/python3.11/site-packages (from node2vec) (1.24.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.55.1 in /opt/conda/lib/python3.11/site-packages (from node2vec) (4.66.1)\n",
      "Requirement already satisfied: Levenshtein==0.25.1 in /opt/conda/lib/python3.11/site-packages (from python-Levenshtein) (0.25.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in /opt/conda/lib/python3.11/site-packages (from Levenshtein==0.25.1->python-Levenshtein) (3.9.4)\n",
      "Requirement already satisfied: csrgraph in /opt/conda/lib/python3.11/site-packages (from nodevectors) (0.1.28)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from nodevectors) (0.57.1)\n",
      "Requirement already satisfied: pandas>=1.0 in /opt/conda/lib/python3.11/site-packages (from nodevectors) (2.1.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from nodevectors) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from nodevectors) (1.3.1)\n",
      "Requirement already satisfied: ipywidgets>=7.7.2 in /opt/conda/lib/python3.11/site-packages (from emblaze) (8.1.1)\n",
      "Requirement already satisfied: affine>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from emblaze) (2.4.0)\n",
      "Requirement already satisfied: colormath>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from emblaze) (3.0.0)\n",
      "Requirement already satisfied: pillow>=8.2.0 in /opt/conda/lib/python3.11/site-packages (from emblaze) (10.1.0)\n",
      "Requirement already satisfied: umap-learn>=0.5.1 in /opt/conda/lib/python3.11/site-packages (from emblaze) (0.5.6)\n",
      "Requirement already satisfied: flask>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from emblaze) (3.0.3)\n",
      "Requirement already satisfied: flask-socketio>=5.1.1 in /opt/conda/lib/python3.11/site-packages (from emblaze) (5.3.6)\n",
      "Requirement already satisfied: eventlet>=0.33.0 in /opt/conda/lib/python3.11/site-packages (from emblaze) (0.36.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (from pymde) (3.8.0)\n",
      "Requirement already satisfied: pynndescent in /opt/conda/lib/python3.11/site-packages (from pymde) (0.5.13)\n",
      "Requirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.11/site-packages (from pymde) (2.3.1)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.11/site-packages (from pymde) (0.18.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from pymde) (2.31.0)\n",
      "Requirement already satisfied: dnspython>=1.15.0 in /opt/conda/lib/python3.11/site-packages (from eventlet>=0.33.0->emblaze) (2.6.1)\n",
      "Requirement already satisfied: greenlet>=1.0 in /opt/conda/lib/python3.11/site-packages (from eventlet>=0.33.0->emblaze) (3.0.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from flask>=1.1.2->emblaze) (3.0.0)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.11/site-packages (from flask>=1.1.2->emblaze) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.11/site-packages (from flask>=1.1.2->emblaze) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.11/site-packages (from flask>=1.1.2->emblaze) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.11/site-packages (from flask>=1.1.2->emblaze) (1.6.3)\n",
      "Requirement already satisfied: python-socketio>=5.0.2 in /opt/conda/lib/python3.11/site-packages (from flask-socketio>=5.1.1->emblaze) (5.11.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.11/site-packages (from gensim<5.0.0,>=4.1.2->node2vec) (7.0.4)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=7.7.2->emblaze) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=7.7.2->emblaze) (8.16.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=7.7.2->emblaze) (5.11.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=7.7.2->emblaze) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=7.7.2->emblaze) (3.0.9)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->nodevectors) (0.40.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0->nodevectors) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0->nodevectors) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0->nodevectors) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->nodevectors) (3.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.1->pymde) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.1->pymde) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.1->pymde) (1.12)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.1->pymde) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.1->pymde) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.1->pymde) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.1->pymde) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.1->pymde) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.1->pymde) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.1->pymde) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.1->pymde) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.1->pymde) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.1->pymde) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.1->pymde) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.1->pymde) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.7.1->pymde) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.1->pymde) (12.5.82)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->pymde) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib->pymde) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib->pymde) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->pymde) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib->pymde) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->pymde) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->pymde) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->pymde) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->pymde) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->pymde) (2023.7.22)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.7.2->emblaze) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.7.2->emblaze) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.7.2->emblaze) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.7.2->emblaze) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.7.2->emblaze) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.7.2->emblaze) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.7.2->emblaze) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.7.2->emblaze) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.7.2->emblaze) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from Jinja2>=3.1.2->flask>=1.1.2->emblaze) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.0->nodevectors) (1.16.0)\n",
      "Requirement already satisfied: bidict>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from python-socketio>=5.0.2->flask-socketio>=5.1.1->emblaze) (0.23.1)\n",
      "Requirement already satisfied: python-engineio>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from python-socketio>=5.0.2->flask-socketio>=5.1.1->emblaze) (4.9.1)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.1.2->node2vec) (1.14.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.7.1->pymde) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.7.2->emblaze) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=7.7.2->emblaze) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets>=7.7.2->emblaze) (0.2.8)\n",
      "Requirement already satisfied: simple-websocket>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from python-engineio>=4.8.0->python-socketio>=5.0.2->flask-socketio>=5.1.1->emblaze) (1.0.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.7.2->emblaze) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.7.2->emblaze) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.7.2->emblaze) (0.2.2)\n",
      "Requirement already satisfied: wsproto in /opt/conda/lib/python3.11/site-packages (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=5.0.2->flask-socketio>=5.1.1->emblaze) (1.2.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=5.0.2->flask-socketio>=5.1.1->emblaze) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!sudo apt update\n",
    "!sudo apt -y install build-essential vim\n",
    "!pip3 install networkx node2vec python-Levenshtein nodevectors emblaze pymde\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_animes_df = pd.read_csv('./work/data/processed-metadata.csv')\n",
    "\n",
    "all_animes = []\n",
    "anime_title_by_id = {}\n",
    "anime_id_by_title = {}\n",
    "anime_ix_by_id = {}\n",
    "anime_by_id = {}\n",
    "\n",
    "i = 0\n",
    "for anime in all_animes_df.itertuples(index=False):\n",
    "    all_animes.append(anime)\n",
    "    anime_title_by_id[anime.id] = anime.title\n",
    "    anime_id_by_title[anime.title] = anime.id\n",
    "    anime_ix_by_id[anime.id] = i\n",
    "    anime_by_id[anime.id] = anime\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings = pd.read_csv('./work/data/collected_animelists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining ratings: 199264878\n",
      "           username  anime_id  my_score  anime_ix\n",
      "0  ------____------     52034       9.1     12722\n",
      "1  ------____------     37403       0.5      9638\n",
      "2  ------____------     22199       9.1      6393\n",
      "3  ------____------     25013       3.3      6725\n",
      "4  ------____------     41433       6.5     11163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only retain the \"username\", \"anime_id\", and \"my_score\" columns\n",
    "ratings = all_ratings[['username', 'anime_id', 'my_score']]\n",
    "# only retain rows where \"my_score\" is not null and greater than or equal to 6\n",
    "ratings = ratings[ratings['my_score'].notnull()]\n",
    "ratings = ratings[ratings['my_score'] > 0]\n",
    "ratings = ratings[ratings['anime_id'].isin(anime_title_by_id.keys())]\n",
    "ratings['anime_ix'] = ratings['anime_id'].apply(lambda x: anime_ix_by_id[x])\n",
    "\n",
    "def scale_rating(rating: int) -> float:\n",
    "    if rating == 10:\n",
    "        return 10.1\n",
    "    if rating == 9:\n",
    "        return 9.1\n",
    "    if rating == 8:\n",
    "        return 6.5\n",
    "    if rating == 7:\n",
    "        return 3.3\n",
    "    if rating == 6:\n",
    "        return 0.5\n",
    "    if rating == 5:\n",
    "        return -1.5\n",
    "    if rating == 4:\n",
    "        return -4.5\n",
    "    if rating == 3:\n",
    "        return -7.5\n",
    "    if rating == 2:\n",
    "        return -10.5\n",
    "    if rating == 1:\n",
    "        return -13.5\n",
    "    raise ValueError(\"Invalid rating: {}\".format(rating))\n",
    "\n",
    "# scale ratings from score to our custom scale\n",
    "ratings['my_score'] = ratings['my_score'].apply(scale_rating)\n",
    "ratings = ratings[ratings['my_score'] > 0]\n",
    "\n",
    "print(\"Remaining ratings:\", ratings.shape[0])\n",
    "print(ratings.head())\n",
    "\n",
    "# collect python garbage\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retained 199264878 ratings out of 199264878 total\n"
     ]
    }
   ],
   "source": [
    "# ratings_subset = ratings.sample(n=5000000)\n",
    "# ratings_subset = ratings[:5000000]\n",
    "ratings_subset = ratings\n",
    "\n",
    "# Retain only ratings of anime that have >=100 ratings\n",
    "ratings_subset = ratings_subset[ratings['anime_id'].isin(anime_title_by_id.keys())]\n",
    "print(f\"Retained {ratings_subset.shape[0]} ratings out of {ratings.shape[0]} total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids: 13647\n",
      "ixs: 13647\n"
     ]
    }
   ],
   "source": [
    "all_ids = set(anime_ix_by_id.keys())\n",
    "all_ixs = set(anime_ix_by_id.values())\n",
    "\n",
    "print(f\"ids: {len(all_ids)}\")\n",
    "print(f\"ixs: {len(all_ixs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 rows\n",
      "Processed 1000000 rows\n",
      "Processed 2000000 rows\n",
      "Processed 3000000 rows\n",
      "Processed 4000000 rows\n",
      "Processed 5000000 rows\n",
      "Processed 6000000 rows\n",
      "Processed 7000000 rows\n",
      "Processed 8000000 rows\n",
      "Processed 9000000 rows\n",
      "Processed 10000000 rows\n",
      "Processed 11000000 rows\n",
      "Processed 12000000 rows\n",
      "Processed 13000000 rows\n",
      "Processed 14000000 rows\n",
      "Processed 15000000 rows\n",
      "Processed 16000000 rows\n",
      "Processed 17000000 rows\n",
      "Processed 18000000 rows\n",
      "Processed 19000000 rows\n",
      "Processed 20000000 rows\n",
      "Processed 21000000 rows\n",
      "Processed 22000000 rows\n",
      "Processed 23000000 rows\n",
      "Processed 24000000 rows\n",
      "Processed 25000000 rows\n",
      "Processed 26000000 rows\n",
      "Processed 27000000 rows\n",
      "Processed 28000000 rows\n",
      "Processed 29000000 rows\n",
      "Processed 30000000 rows\n",
      "Processed 31000000 rows\n",
      "Processed 32000000 rows\n",
      "Processed 33000000 rows\n",
      "Processed 34000000 rows\n",
      "Processed 35000000 rows\n",
      "Processed 36000000 rows\n",
      "Processed 37000000 rows\n",
      "Processed 38000000 rows\n",
      "Processed 39000000 rows\n",
      "Processed 40000000 rows\n",
      "Processed 41000000 rows\n",
      "Processed 42000000 rows\n",
      "Processed 43000000 rows\n",
      "Processed 44000000 rows\n",
      "Processed 45000000 rows\n",
      "Processed 46000000 rows\n",
      "Processed 47000000 rows\n",
      "Processed 48000000 rows\n",
      "Processed 49000000 rows\n",
      "Processed 50000000 rows\n",
      "Processed 51000000 rows\n",
      "Processed 52000000 rows\n",
      "Processed 53000000 rows\n",
      "Processed 54000000 rows\n",
      "Processed 55000000 rows\n",
      "Processed 56000000 rows\n",
      "Processed 57000000 rows\n",
      "Processed 58000000 rows\n",
      "Processed 59000000 rows\n",
      "Processed 60000000 rows\n",
      "Processed 61000000 rows\n",
      "Processed 62000000 rows\n",
      "Processed 63000000 rows\n",
      "Processed 64000000 rows\n",
      "Processed 65000000 rows\n",
      "Processed 66000000 rows\n",
      "Processed 67000000 rows\n",
      "Processed 68000000 rows\n",
      "Processed 69000000 rows\n",
      "Processed 70000000 rows\n",
      "Processed 71000000 rows\n",
      "Processed 72000000 rows\n",
      "Processed 73000000 rows\n",
      "Processed 74000000 rows\n",
      "Processed 75000000 rows\n",
      "Processed 76000000 rows\n",
      "Processed 77000000 rows\n",
      "Processed 78000000 rows\n",
      "Processed 79000000 rows\n",
      "Processed 80000000 rows\n",
      "Processed 81000000 rows\n",
      "Processed 82000000 rows\n",
      "Processed 83000000 rows\n",
      "Processed 84000000 rows\n",
      "Processed 85000000 rows\n",
      "Processed 86000000 rows\n",
      "Processed 87000000 rows\n",
      "Processed 88000000 rows\n",
      "Processed 89000000 rows\n",
      "Processed 90000000 rows\n",
      "Processed 91000000 rows\n",
      "Processed 92000000 rows\n",
      "Processed 93000000 rows\n",
      "Processed 94000000 rows\n",
      "Processed 95000000 rows\n",
      "Processed 96000000 rows\n",
      "Processed 97000000 rows\n",
      "Processed 98000000 rows\n",
      "Processed 99000000 rows\n",
      "Processed 100000000 rows\n",
      "Processed 101000000 rows\n",
      "Processed 102000000 rows\n",
      "Processed 103000000 rows\n",
      "Processed 104000000 rows\n",
      "Processed 105000000 rows\n",
      "Processed 106000000 rows\n",
      "Processed 107000000 rows\n",
      "Processed 108000000 rows\n",
      "Processed 109000000 rows\n",
      "Processed 110000000 rows\n",
      "Processed 111000000 rows\n",
      "Processed 112000000 rows\n",
      "Processed 113000000 rows\n",
      "Processed 114000000 rows\n",
      "Processed 115000000 rows\n",
      "Processed 116000000 rows\n",
      "Processed 117000000 rows\n",
      "Processed 118000000 rows\n",
      "Processed 119000000 rows\n",
      "Processed 120000000 rows\n",
      "Processed 121000000 rows\n",
      "Processed 122000000 rows\n",
      "Processed 123000000 rows\n",
      "Processed 124000000 rows\n",
      "Processed 125000000 rows\n",
      "Processed 126000000 rows\n",
      "Processed 127000000 rows\n",
      "Processed 128000000 rows\n",
      "Processed 129000000 rows\n",
      "Processed 130000000 rows\n",
      "Processed 131000000 rows\n",
      "Processed 132000000 rows\n",
      "Processed 133000000 rows\n",
      "Processed 134000000 rows\n",
      "Processed 135000000 rows\n",
      "Processed 136000000 rows\n",
      "Processed 137000000 rows\n",
      "Processed 138000000 rows\n",
      "Processed 139000000 rows\n",
      "Processed 140000000 rows\n",
      "Processed 141000000 rows\n",
      "Processed 142000000 rows\n",
      "Processed 143000000 rows\n",
      "Processed 144000000 rows\n",
      "Processed 145000000 rows\n",
      "Processed 146000000 rows\n",
      "Processed 147000000 rows\n",
      "Processed 148000000 rows\n",
      "Processed 149000000 rows\n",
      "Processed 150000000 rows\n",
      "Processed 151000000 rows\n",
      "Processed 152000000 rows\n",
      "Processed 153000000 rows\n",
      "Processed 154000000 rows\n",
      "Processed 155000000 rows\n",
      "Processed 156000000 rows\n",
      "Processed 157000000 rows\n",
      "Processed 158000000 rows\n",
      "Processed 159000000 rows\n",
      "Processed 160000000 rows\n",
      "Processed 161000000 rows\n",
      "Processed 162000000 rows\n",
      "Processed 163000000 rows\n",
      "Processed 164000000 rows\n",
      "Processed 165000000 rows\n",
      "Processed 166000000 rows\n",
      "Processed 167000000 rows\n",
      "Processed 168000000 rows\n",
      "Processed 169000000 rows\n",
      "Processed 170000000 rows\n",
      "Processed 171000000 rows\n",
      "Processed 172000000 rows\n",
      "Processed 173000000 rows\n",
      "Processed 174000000 rows\n",
      "Processed 175000000 rows\n",
      "Processed 176000000 rows\n",
      "Processed 177000000 rows\n",
      "Processed 178000000 rows\n",
      "Processed 179000000 rows\n",
      "Processed 180000000 rows\n",
      "Processed 181000000 rows\n",
      "Processed 182000000 rows\n",
      "Processed 183000000 rows\n",
      "Processed 184000000 rows\n",
      "Processed 185000000 rows\n",
      "Processed 186000000 rows\n",
      "Processed 187000000 rows\n",
      "Processed 188000000 rows\n",
      "Processed 189000000 rows\n",
      "Processed 190000000 rows\n",
      "Processed 191000000 rows\n",
      "Processed 192000000 rows\n",
      "Processed 193000000 rows\n",
      "Processed 194000000 rows\n",
      "Processed 195000000 rows\n",
      "Processed 196000000 rows\n",
      "Processed 197000000 rows\n",
      "Processed 198000000 rows\n",
      "Processed 199000000 rows\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "ratings_by_username = defaultdict(list)\n",
    "\n",
    "i = 0\n",
    "for row in ratings_subset.itertuples():\n",
    "    if i % 1000000 == 0:\n",
    "        print(f\"Processed {i} rows\")\n",
    "    i += 1\n",
    "\n",
    "    rating = row.my_score\n",
    "    if rating < 0:\n",
    "        continue\n",
    "    anime_ix = anime_ix_by_id[row.anime_id]\n",
    "    ratings_by_username[row.username].append((anime_ix, rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500000 rows\n",
      "Removed 4 duplicate ratings for user nan\n",
      "Processed 1000000 rows\n"
     ]
    }
   ],
   "source": [
    "# for each user's ratings, deduplicate.\n",
    "processed_rows = 0\n",
    "for username in ratings_by_username.keys():\n",
    "    before_len = len(ratings_by_username[username])\n",
    "    ratings_by_username[username] = list(set(ratings_by_username[username]))\n",
    "    after_len = len(ratings_by_username[username])\n",
    "    if before_len != after_len:\n",
    "        print(f\"Removed {before_len - after_len} duplicate ratings for user {username}\")\n",
    "    processed_rows += 1\n",
    "    if processed_rows % 500000 == 0:\n",
    "        print(f\"Processed {processed_rows} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings = [(np.asarray([anime_ix for anime_ix, rating in ratings]), np.asarray([rating for anime_ix, rating in ratings])) for ratings in ratings_by_username.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/numba/core/decorators.py:282: RuntimeWarning: nopython is set for njit and is ignored\n",
      "  warnings.warn('nopython is set for njit and is ignored', RuntimeWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/numba/core/ir_utils.py:2149: NumbaPendingDeprecationWarning: \u001b[1m\n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'ratings' of function 'compute_cooccurrence_matrix'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\u001b[1m\n",
      "File \"../../tmp/ipykernel_13023/3779232740.py\", line 5:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users to process: 1440214\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "self.setup has not been called",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsers to process: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ratings)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m cooccurrence_matrix \u001b[38;5;241m=\u001b[39m compute_cooccurrence_matrix(\u001b[38;5;28mlen\u001b[39m(anime_title_by_id), ratings)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mcompute_cooccurrence_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_diagnostics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/numba/core/dispatcher.py:1027\u001b[0m, in \u001b[0;36mDispatcher.parallel_diagnostics\u001b[0;34m(self, signature, level)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     dump(signature)\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1027\u001b[0m     \u001b[43m[\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignatures\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/numba/core/dispatcher.py:1027\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     dump(signature)\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1027\u001b[0m     [\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignatures]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/numba/core/dispatcher.py:1023\u001b[0m, in \u001b[0;36mDispatcher.parallel_diagnostics.<locals>.dump\u001b[0;34m(sig)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo parfors diagnostic available, is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparallel=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m set?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m-> 1023\u001b[0m \u001b[43mpfdiag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/numba/parfors/parfor.py:1235\u001b[0m, in \u001b[0;36mParforDiagnostics.dump\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(\u001b[38;5;28mself\u001b[39m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_setup:\n\u001b[0;32m-> 1235\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself.setup has not been called\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1236\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc_ir\u001b[38;5;241m.\u001b[39mfunc_id\u001b[38;5;241m.\u001b[39mfunc_qualname\n\u001b[1;32m   1237\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc_ir\u001b[38;5;241m.\u001b[39mloc\n",
      "\u001b[0;31mRuntimeError\u001b[0m: self.setup has not been called"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "from numba.np.ufunc import parallel\n",
    "\n",
    "@njit(parallel=False, nopython=True)\n",
    "def compute_cooccurrence_matrix(anime_count: int, ratings: list[(np.array, np.array)]) -> np.ndarray:\n",
    "    cooccurrence_matrix = np.zeros((anime_count, anime_count))\n",
    "\n",
    "    for anime_indices, ratings in ratings:\n",
    "        rating_count_for_user = len(anime_indices)\n",
    "\n",
    "        for i in range(rating_count_for_user):\n",
    "            for j in range(rating_count_for_user):\n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                cooccurrence_matrix[anime_indices[i], anime_indices[j]] += ratings[i] * ratings[j]\n",
    "\n",
    "    return cooccurrence_matrix\n",
    "\n",
    "print(f\"Users to process: {len(ratings)}\")\n",
    "cooccurrence_matrix = compute_cooccurrence_matrix(len(anime_title_by_id), ratings)\n",
    "\n",
    "# compute_cooccurrence_matrix.parallel_diagnostics(level=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4854968.439999605"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooccurrence_matrix[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the co-occurrence matrix to compressed binary numpy file\n",
    "np.savez_compressed('./work/data/cooccurrence_matrix.npz', cooccurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooccurrence_matrix = np.load('./work/data/cooccurrence_matrix.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(40.0, 'Kill Me Baby: Butsuzou Kegatte Nise Halloween'),\n",
       " (0.2, 'Kirara Fantasia'),\n",
       " (1.224744871391589, 'Lucky☆Star'),\n",
       " (1.118033988749895, 'Nichijou'),\n",
       " (1.118033988749895, 'Acchi Kocchi'),\n",
       " (1.0, 'Yuyushiki'),\n",
       " (0.8660254037844386, 'Akuma no Riddle'),\n",
       " (0.8660254037844386, 'Danshi Koukousei no Nichijou'),\n",
       " (0.8660254037844386, 'Aho Girl'),\n",
       " (0.7071067811865476, 'Gugure! Kokkuri-san'),\n",
       " (0.7071067811865476, 'Keroro Gunsou'),\n",
       " (0.7071067811865476, 'Hetalia Axis Powers')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "def score_num_recommendations(num_recommendations):\n",
    "    return math.sqrt(num_recommendations) / 2.\n",
    "\n",
    "def parse_extra(item):\n",
    "    related = json.loads(item.related_anime)\n",
    "    related = [(r['node']['id'], 0.2 if r['relation_type'] == 'character' else 40) for r in related]\n",
    "    recommended = [(r['node']['id'], score_num_recommendations(r['num_recommendations'])) for r in json.loads(item.recommendations)]\n",
    "    return [(anime_ix_by_id.get(id), score) for id, score in related + recommended if anime_ix_by_id.get(id) is not None]\n",
    "\n",
    "related_by_anime_ix = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "for item in all_animes:\n",
    "    anime_ix = anime_ix_by_id.get(item.id)\n",
    "    if anime_ix is None:\n",
    "        continue\n",
    "    related_for_item = parse_extra(item)\n",
    "    entry = related_by_anime_ix[anime_ix]\n",
    "    for ix, weight in related_for_item:\n",
    "        entry[ix] += weight\n",
    "\n",
    "kill_me_baby_id = 11079\n",
    "kill_me_baby_ix = anime_ix_by_id[kill_me_baby_id]\n",
    "[(score, all_animes[ix].title) for ix, score in related_by_anime_ix[kill_me_baby_ix].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooccurrence_matrix_wextra = cooccurrence_matrix.copy()\n",
    "\n",
    "for anime_0_ix in range(len(cooccurrence_matrix)):\n",
    "    related_for_anime0 = related_by_anime_ix[anime_0_ix]\n",
    "    max_weight = cooccurrence_matrix[anime_0_ix].max()\n",
    "\n",
    "    for ix, weight in related_for_anime0.items():\n",
    "        if ix == anime_0_ix:\n",
    "            continue\n",
    "        cooccurrence_matrix_wextra[anime_0_ix, ix] += weight * max_weight\n",
    "\n",
    "np.save('./work/data/cooccurrence_matrix_wextra.npy', cooccurrence_matrix_wextra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "603813686.4405583"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooccurrence_matrix_wextra[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m anime_0_ix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cooccurrence_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     12\u001b[0m     row \u001b[38;5;241m=\u001b[39m cooccurrence_matrix[anime_0_ix]\n\u001b[0;32m---> 13\u001b[0m     top_edges \u001b[38;5;241m=\u001b[39m \u001b[43mget_topn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     top_related_anime_ixs_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([ix \u001b[38;5;28;01mfor\u001b[39;00m ix, weight \u001b[38;5;129;01min\u001b[39;00m top_edges])\n\u001b[1;32m     16\u001b[0m     top_magnitude \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(top_edges) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m top_edges[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m, in \u001b[0;36mget_topn\u001b[0;34m(weights, topn)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_topn\u001b[39m(weights, topn):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(weights), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:topn]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "graph = nx.Graph()\n",
    "\n",
    "def get_topn(weights, topn):\n",
    "    return sorted(enumerate(weights), key=lambda x: x[1], reverse=True)[:topn]\n",
    "\n",
    "topn = 40\n",
    "\n",
    "def get_extra_topn(rating_count):\n",
    "    return int(max(math.pow(rating_count, 0.46) * 0.4 - 10, 0))\n",
    "\n",
    "for anime_0_ix in range(cooccurrence_matrix.shape[0]):\n",
    "    row = cooccurrence_matrix[anime_0_ix]\n",
    "    top_edges = get_topn(row, topn)\n",
    "    top_related_anime_ixs_set = set([ix for ix, weight in top_edges])\n",
    "\n",
    "    top_magnitude = 0 if len(top_edges) == 0 else top_edges[0][1]\n",
    "    if top_magnitude == 0:\n",
    "        continue\n",
    "    related_for_anime0 = related_by_anime_ix[anime_0_ix]\n",
    "\n",
    "    for related_anime_ix, related_weight in related_for_anime0.items():\n",
    "        if related_anime_ix in top_related_anime_ixs_set:\n",
    "            continue\n",
    "        top_edges.append((related_anime_ix, 0.))\n",
    "\n",
    "    for anime_1_ix, base_weight in top_edges:\n",
    "        extra_weight = related_for_anime0[anime_1_ix]\n",
    "        # This may need to be tuned\n",
    "        weight = base_weight + extra_weight * top_magnitude * 1.\n",
    "        graph.add_edge(anime_0_ix, anime_1_ix, weight=weight)\n",
    "\n",
    "print(\"Edges:\", graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/networkx/linalg/graphmatrix.py:187: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  return adjacency_matrix(G, nodelist, dtype, weight)\n"
     ]
    }
   ],
   "source": [
    "import csrgraph as cg\n",
    "import nodevectors\n",
    "\n",
    "cgraph = cg.csrgraph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0035\t:  12%|█▏        | 42/350 [00:49<06:01,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged! Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dimensions = 10\n",
    "order = 2\n",
    "algo = \"ggvec\"\n",
    "\n",
    "embedding_model = None\n",
    "if algo == \"ggvec\":\n",
    "    embedding_model = nodevectors.GGVec(n_components=dimensions, learning_rate=0.01, negative_ratio=0.6, verbose=True, order=order)\n",
    "elif algo == \"node2vec\":\n",
    "    embedding_model = nodevectors.Node2Vec(walklen=8, epochs=50, return_weight=2., neighbor_weight=1., n_components=dimensions, threads=14)\n",
    "elif algo == \"ProNE\":\n",
    "    embedding_model = nodevectors.ProNE(n_components=dimensions)\n",
    "\n",
    "embeddings = embedding_model.fit_transform(cgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key length: 11898; weight length: 11898; anime_count: 11898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/embedding_ggvec_full_posonly_wextra_top40_10d_order2.w2v'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = [int(n) for n in cgraph.nodes()]\n",
    "\n",
    "print(f\"key length: {len(keys)}; weight length: {len(embeddings)}; anime_count: {len(all_animes)}\")\n",
    "\n",
    "fname = f\"../data/embedding_{algo}_full_posonly_wextra_top{topn}_{dimensions}d_order{order}.w2v\"\n",
    "with open(fname, 'wt') as f:\n",
    "    tab = ' '\n",
    "    nl = '\\n'\n",
    "    f.write(f\"{len(keys)}{tab}{dimensions}{nl}\")\n",
    "    for key, embedding in zip(keys, embeddings):\n",
    "        f.write(f\"{key}{tab}{tab.join(map(str, embedding))}{nl}\")\n",
    "fname"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
