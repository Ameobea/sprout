{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000000 ratings\n",
      "Processed 2000000 ratings\n",
      "Processed 3000000 ratings\n",
      "Processed 4000000 ratings\n",
      "Processed 5000000 ratings\n",
      "Processed 6000000 ratings\n",
      "Processed 7000000 ratings\n",
      "Processed 8000000 ratings\n",
      "Processed 9000000 ratings\n",
      "Processed 10000000 ratings\n",
      "Processed 11000000 ratings\n",
      "Processed 12000000 ratings\n",
      "Processed 13000000 ratings\n",
      "Processed 14000000 ratings\n",
      "Processed 15000000 ratings\n",
      "Processed 16000000 ratings\n",
      "Processed 17000000 ratings\n",
      "Processed 18000000 ratings\n",
      "Processed 19000000 ratings\n",
      "Processed 20000000 ratings\n",
      "Processed 21000000 ratings\n",
      "Processed 22000000 ratings\n",
      "Processed 23000000 ratings\n",
      "Processed 24000000 ratings\n",
      "Processed 25000000 ratings\n",
      "Processed 26000000 ratings\n",
      "Processed 27000000 ratings\n",
      "Processed 28000000 ratings\n",
      "Processed 29000000 ratings\n",
      "Processed 30000000 ratings\n",
      "Processed 31000000 ratings\n",
      "Processed 32000000 ratings\n",
      "Processed 33000000 ratings\n",
      "Processed 34000000 ratings\n",
      "Processed 35000000 ratings\n",
      "Processed 36000000 ratings\n",
      "Processed 37000000 ratings\n",
      "Processed 38000000 ratings\n",
      "Processed 39000000 ratings\n",
      "Processed 40000000 ratings\n",
      "Processed 41000000 ratings\n",
      "Processed 42000000 ratings\n",
      "Processed 43000000 ratings\n",
      "Processed 44000000 ratings\n",
      "Processed 45000000 ratings\n",
      "Processed 46000000 ratings\n",
      "Processed 47000000 ratings\n",
      "Processed 48000000 ratings\n",
      "Processed 49000000 ratings\n",
      "Processed 50000000 ratings\n",
      "Processed 51000000 ratings\n",
      "Processed 52000000 ratings\n",
      "Processed 53000000 ratings\n",
      "Processed 54000000 ratings\n",
      "Processed 55000000 ratings\n",
      "Processed 56000000 ratings\n",
      "Processed 57000000 ratings\n",
      "Processed 58000000 ratings\n",
      "Processed 59000000 ratings\n",
      "Processed 60000000 ratings\n",
      "Processed 61000000 ratings\n",
      "Processed 62000000 ratings\n",
      "Processed 63000000 ratings\n",
      "Processed 64000000 ratings\n",
      "Processed 65000000 ratings\n",
      "Processed 66000000 ratings\n",
      "Processed 67000000 ratings\n",
      "Processed 68000000 ratings\n",
      "Processed 69000000 ratings\n",
      "Processed 70000000 ratings\n",
      "Processed 71000000 ratings\n",
      "Processed 72000000 ratings\n",
      "Processed 73000000 ratings\n",
      "Processed 74000000 ratings\n",
      "Processed 75000000 ratings\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "all_ratings = pd.read_csv('./work/data/collected_animelists.csv')\n",
    "\n",
    "class RatingSumCounter:\n",
    "    sum = 0\n",
    "    count = 0\n",
    "\n",
    "# Compute total + average ratings per anime\n",
    "rating_sums_by_anime = defaultdict(lambda: RatingSumCounter())\n",
    "\n",
    "i = 0\n",
    "for row in all_ratings.itertuples():\n",
    "    anime_id = row.anime_id\n",
    "    rating = row.my_score\n",
    "    ratings = rating_sums_by_anime[anime_id]\n",
    "    ratings.sum += rating\n",
    "    ratings.count += 1\n",
    "    \n",
    "    i += 1\n",
    "    if i % 1000000 == 0:\n",
    "        print(f\"Processed {i} ratings\")\n",
    "\n",
    "# Exported from MySQL\n",
    "with open('./work/data/anime-metadata.csv') as f:\n",
    "    reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "    # skip header row\n",
    "    next(reader)\n",
    "    \n",
    "    # Read by the webapp backend\n",
    "    with open('./work/data/processed-metadata.csv', 'wt') as f:\n",
    "        writer = csv.writer(f, delimiter=',', quotechar='\"')\n",
    "        headers = ['id', 'title', 'title_english', 'related_anime', 'recommendations', 'aired_from_year', 'rating_count', 'average_rating', 'media_type']\n",
    "        writer.writerow(headers)\n",
    "\n",
    "        for row in reader:\n",
    "            anime_id = int(row[0])\n",
    "            rating_count = rating_sums_by_anime[anime_id].count\n",
    "            if rating_count < 100:\n",
    "                continue\n",
    "            metadata = json.loads(row[1])\n",
    "            title = metadata['title']\n",
    "            title_english = metadata['alternative_titles']['en'] if 'en' in metadata['alternative_titles'] else title\n",
    "            related_anime = json.dumps(metadata.get('related_anime', []))\n",
    "            recommendations = json.dumps(metadata.get('recommendations', []))\n",
    "            aired_from_year = int(metadata.get('start_date', '1900')[:4])\n",
    "            average_rating = rating_sums_by_anime[anime_id].sum / rating_count if rating_count > 0 else 0\n",
    "            media_type = metadata['media_type']\n",
    "            writer.writerow([anime_id, title, title_english, related_anime, recommendations, aired_from_year, rating_count, average_rating, media_type])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
